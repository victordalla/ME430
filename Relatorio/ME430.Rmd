---
output: 
  pdf_document:
    template: template.tex 
    number_sections: true
bibliography: bibliography.bib
papersize: a4paper
fontsize: 11pt
documentclass: article
geometry: margin=2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE,
                      warning = FALSE,
                      tidy.opts = list(width.cutoff = 60),
                      tidy = TRUE)
options(OutDec = ",", 
        digits = 4, 
        knitr.table.format = "latex", 
        xtable.comment = FALSE)
```


\begin{titlepage} 

\begin{center} 
{\large Universidade Estadual de Campinas}\\[0.2cm] 
{\large Instituto de Matemática, Estatística e Computação Científica}\\[0.2cm] 
{\large Departamento de Estatística - ME430}\\[4cm]

{\bf \huge Trabalho de ME430}\\
{\bf \Large Questão 2 da Lista IV}\\[6cm]


{\large Grupo}\\[0.2cm]
{\large Victor 206493, Jordão 170844, Nicole 204186,  Leticia 201357}\\[0.2cm]
{\large Prof. Dr. Caio Azevedo}\\[6cm]

{\large Campinas}\\[0.2cm]
{\large 2018}
\end{center}

\end{titlepage}


# Introdução

```{r lib}
library(readr)
library(readxl)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
```

```{r leitura}
questionario <- read_csv2('../dados/2017_quest.txt')
questionario$APROVA1 <- ifelse(is.na(questionario$APROVA1), 0, 1)
colnames(questionario)[1] <- 'EMPCT'

conv_matr <- read_csv2('../dados/ConvocadosMatriculados.csv')
conv_matr$CONVOCADO <- ifelse(is.na(conv_matr$CONVOCADO), 0, 1)
conv_matr$MATRICULADO <- ifelse(is.na(conv_matr$MATRICULADO), 0, 1)

fase1 <- read_csv2('../dados/Fase1TipoQ.csv', 
                   col_types = cols_only('EMPCT' = col_integer(), 
                                         'TOTAL' = col_integer()))

opcoes <- read_xls('../dados/Opcoes.xls')

# DADOS DUPLICADOS 
conv_matr %<>% subset(!duplicated(conv_matr$EMPCT))

N <- nrow(fase1)

```

Este trabalho consiste na aplicação de técnicas aprendidas na disciplina ME430 - Técnicas de Amostragem - em um conjunto de dados da COMVEST. Esse conjunto de dados possui informações de `r N` candidatos ao vestibular 2017 e seus desempenhos nele. O objetivo é estimar i) a média da pontuação total de cada cadiadato, ii) a proporção de candidatos que cursaram todo o ensino médio em escola pública e iii) o total de quartos nas casas de todos os candidatos. As subseções *Média*, *Proporção* e *Total* nas seções *Análise Descritiva* e *Análise Inferencial* se referem a, respectivamente, i), ii) e iii). As amostragens realizadas foram artificiais, visto que há acesso às informações de todos os elementos da população (candidatos ao vestibular).

# Análise Descritiva

## Média


```{r dados-media}
dados_media <- fase1 %>% left_join(questionario)

# 1: NA, 2: 5 SM ou menos, 3: entre 5 e 10 SM, 4: mais de 10 SM
dados_media$Q14[dados_media$Q14 == 0] <- 1
dados_media$Q14[dados_media$Q14 < 5 & dados_media$Q14 != 1] <- 2
dados_media$Q14[dados_media$Q14 == 5 | dados_media$Q14 == 6] <- 3
dados_media$Q14[dados_media$Q14 > 6] <- 4
```

```{r piloto-media}
# estratos
estratos <- quo(Q14)
N_h <- group_by(dados_media, !! estratos) %>% 
  summarise(N_h = n()) %>% 
  .$N_h
W_h <- N_h / N
H <- length(N_h)

# amostra piloto
n_piloto <- 200
piloto_media <- select(dados_media, EMPCT, TOTAL, !! estratos) %>% 
  group_by(!! estratos) %>% 
  mutate(N_h = n()) %>% 
  sample_frac(size = n_piloto/N, weight = N_h)

stats <- summarise(piloto_media, 
                   n_h = n(), 
                   mean_h = mean(TOTAL), 
                   var_h = var(TOTAL), 
                   sd_h = sd(TOTAL)) %>% 
  arrange(Q14)

mu_es <- sum(W_h * stats$mean_h)
var_d = sum(W_h * stats$var_h)
var_e = sum(W_h * (stats$mean_h - mu_es)^2)
var_chapeu <- var_d + var_e
```

```{r tamanho-media}
delta <- 1
z_gamma <- qnorm(0.95)

# tamanhos amostrais
n_AASs <- ceiling(1 / ((delta^2 / (z_gamma^2 * var_chapeu)) + (1/N)))
# Slide 18 http://www.ime.unicamp.br/~cnaber/aula_AE%20P2%20Amost%202S%202018.pdf
n_AE_AP <- ceiling(1 / ((delta^2 / (z_gamma^2 * sum(W_h*stats$var_h))) + (1/N)))
n_h <- ceiling(n_AE_AP * (N_h*stats$var_h) / sum(N_h*stats$var_h))
n <- sum(n_h)
```


Inicialmente, para estimar $\mu$, a pontuação média de todos os candidatos na 1ª fase, foi coletada uma amostra piloto de tamanho `r n_piloto` sob uma amostragem estratificada (AE) com $H = `r H`$ estratos, especificados a seguir, a fim de determinar o tamanho amostral e o plano amostral mais adequado. Para isso, foi estimado a variância $\sigma_{\mu}^2 = \frac{1}{N} \sum_{i=1}^N y_i$ da pontuação e a variância nos estratos $\sigma_{\mu h}^2 = \frac{1}{N_h} \sum_{i=1}^{N_h} y_{ih}$, onde $N = `r N`$ é o número de candidatos, $N_h$ é o tamanho populacional do h-ésimo estrato, $y_i$ é a pontuação do i-ésimo candiadato e $y_{ih}$ é a pontuação do i-ésimo candidato no h-ésimo estrato. A alocação dos estratos foi feita segundo alocação proporcional (AP). Nesse tipo de alocação, o tamanho amostral do h-ésimo estrato é $n_h = n \frac{N_h}{N}$.

Os estratos escolhidos foram as respostas agrupadas da Questão 14 no questionário que cada candidato deveria responder. Essa questão é como segue: "Somando a sua renda com a renda das pessoas que moram com você, quanto é, aproximadamente, a renda familiar mensal? O valor do salário mínimo (SM) é de R$ 724,00". As respostas agrupadas determinam os seguintes estratos: 1 - dados faltantes, 2 - até 5 SM, 3 - entre 5 e 10 SM e 4 - mais que 10 SM.

A amostra piloto resultou em uma estimativa de $\hat{\sigma_{\mu}^2} = \hat{\sigma_d^2} + \hat{\sigma_e^2} = `r var_d + var_e`$ **(HELP WANTED)** para a variância $\sigma_{\mu}^2$, onde $\hat{\sigma_d^2} = \sum_{i=1}^H \frac{N_h}{N}\hat{\sigma_h^2}$ é a variância estimada no h-ésimo estrato e $\hat{\sigma_e^2} = \sum_{i=1}^H \frac{N_h}{N}(\hat{\mu}_h-\mu)^2$ é a variância estimada das médias dos estratos. De posse dessa informação, para realizar AE com AP e erro de estimativa $\delta = `r delta`$, é preciso um tamanho de amostra $n$ de pelo menos $n \geq \frac{z_{0.95}^2}{\delta^2} \sum_{i=1}^H\frac{N_h}{N} \hat{\sigma^2}$ **(OU SERIA S^2 AQUI?)**  para garantir que $P(|\mu - \hat{\mu}| \leq \delta) \geq 0.95$ \cite{bolfarine2005elementos}, onde $z_{0.95}$ é o 95-quantil da normal padrão. Portanto, para os dados coletados, são necessárias pelo menos `r n_AE_AP` unidades amostrais.

Por outro lado, uma amostragem aeleatória simples sem reposição (AASs) requer $\Big(\frac{\delta^2}{\hat{s^2}z_{0.95}} + \frac{1}{N}\Big) ^ {-1}$ para garantir que $P(|\mu - \hat{\mu}| \leq \delta) \geq 0.95$ \cite{bolfarine2005elementos},  onde $s_{\mu}^2 = \frac{n\sigma^2}{n-1}$. Para os dados observados, esse plano amostral precisa de `r n_AASs` unidades amostrais, número maior que no caso AE com AP. Portanto, é mais vantajoso realizar AE com AP. 

É possível tornar a amostragem ainda mais robusta, utilizando a alocação ótima de Neyman (AON), que minimiza a variância da estimativa $\hat{\mu} = \sum$  para $\mu$ quando o custo de amostragem é homogêneo entre os estratos. Usando AON, temos que $n_h = n \frac{N_h\sigma_h}{\sum_{i=1}^HN_h\sigma_h}$ \cite{bolfarine2005elementos}. Como $\sigma_h$ não são valores conhecidos, foi usado $\hat{\sigma_h^2}$. As informações obtidas da amostra piloto e referentes à amostragem AE com AON estão resumidas na Tabela \ref{tab:resumo-media}. Observe que $n = `r n`$ tem `r n-n_AE_AP` unidades a mais sob AON, pelo fato de ter sido pego o menor inteiro maior que a expressão que determina $n_h$.

\begin{table}[!h]
\centering
\caption{Informações de cada estrato $h$: $N_h$ - número de cadidatos no estrato, $\hat{\sigma_h^2}$ - variância no estrato estimada na amostra piloto, $n_h$ - tamanho amostral do estrato segundo AON.}
\label{tab:resumo-media}
\fontsize{11}{13}\selectfont

\begin{tabular}{l|lll}
$h$ & $N_h$ & $\hat{\sigma_h^2}$ & $n_h$ \\
\hline
0 & `r N_h[1]` & `r stats$var_h[1]` & `r n_h[1]` \\
1 & `r N_h[2]` & `r stats$var_h[2]` & `r n_h[2]` \\
2 & `r N_h[3]` & `r stats$var_h[3]` & `r n_h[3]` \\
4 & `r N_h[4]` & `r stats$var_h[4]` & `r n_h[4]` \\
\end{tabular}
\end{table}


## Proporção

```{r}
# Proporcao de alunos de escola pública

pub <- questionario[questionario$Q3 == 1, ]$EMPCT
priv <- questionario[questionario$Q3 != 1, ]$EMPCT

N_h <- c(length(pub), length(priv))
N <- dim(questionario)[1]
W_h <- N_h / N
H <- 2 # quantidade de extratos

# Amostra piloto 

n_piloto <- c(50, 50)
# n_piloto <- c(250, 250)

amostra_pil_1 <- sample_n(questionario %>% filter(EMPCT %in% pub), n_piloto[1])
amostra_pil_2 <- sample_n(questionario %>% filter(EMPCT %in% priv), n_piloto[2])

p_piloto <- c(sum(amostra_pil_1$Q4 == 1) / dim(amostra_pil_1)[1],
              sum(amostra_pil_2$Q4 == 1) / dim(amostra_pil_2)[1])

s2hat_pil <- n_piloto / (n_piloto - 1) * p_piloto * (1 - p_piloto)

varhat_phat_pil <- (1 - n_piloto/N) * s2hat_pil / n_piloto


# Tamanhos amostrais

# Slide 18
# http://www.ime.unicamp.br/~cnaber/aula_AE%20P2%20Amost%202S%202018.pdf
delta = 0.01 # erro de estimação DUVIDA!!!
z_gamma = qnorm(0.975) # para 0.95 de IC
n <- 1 / (delta^2/(z_gamma^2 * sum(W_h * s2hat_pil)) + 1/N)

n_h <- n * N_h * sqrt(s2hat_pil) / (sum(N_h * sqrt(s2hat_pil)))

# Amostragem final

amostra_1 <- sample_n(questionario %>% filter(EMPCT %in% pub), n_h[1])
amostra_2 <- sample_n(questionario %>% filter(EMPCT %in% priv), n_h[2])

phat_h <- c(sum(amostra_1$Q4 == 1) / dim(amostra_1)[1],
            sum(amostra_2$Q4 == 1) / dim(amostra_2)[1])

phat <- sum(W_h * phat_h)
```


## Total


# Análise Inferencial

## Média


## Proporção


## Total


# Conlcusões

\bibliographystyle{plain}
\bibliography{bibliography}

